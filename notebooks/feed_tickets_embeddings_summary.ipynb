{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e948bb43-03cc-467d-8f9b-2acc54edf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import base64\n",
    "import hashlib\n",
    "from langchain.chains.combine_documents.base import BaseCombineDocumentsChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from google.oauth2.service_account import Credentials\n",
    "from google.cloud import bigquery\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2867dc97-8345-42a5-9910-51d2e21ea416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseService:\n",
    "\n",
    "    def __init__(self):\n",
    "        db_user=''\n",
    "        db_password=''\n",
    "        db_database=''\n",
    "        db_port='5432'\n",
    "        db_host=''\n",
    "        self.connection_str = f\"host='{db_host}' port='{db_port}' dbname='{db_database}' user='{db_user}' password='{db_password}'\"\n",
    "\n",
    "    def _get_database_connection(self):\n",
    "        return psycopg2.connect(self.connection_str)\n",
    "\n",
    "    def run_select_statement(self, select_statement: str, vars=None):\n",
    "        \n",
    "        try:\n",
    "            conn = self._get_database_connection()\n",
    "            register_vector(conn)\n",
    "        except Exception as e:\n",
    "            print(f'Connecting to database failed. {e}')\n",
    "            return []\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(select_statement, vars=vars)\n",
    "            fields = [field_md[0] for field_md in cursor.description]\n",
    "            result = cursor.fetchall()\n",
    "            result = [dict(zip(fields, row)) for row in result]\n",
    "        except Exception as e:\n",
    "            print(f'Fetching resuls from database failed. {e}\\nSelect statement: {select_statement}')\n",
    "            conn.rollback()\n",
    "            result = []\n",
    "\n",
    "        return result\n",
    "    \n",
    "    # Delete all records from a table\n",
    "    def run_dml_delete_statement(self, table: str):\n",
    "        \n",
    "        try:\n",
    "            conn = self._get_database_connection()\n",
    "            register_vector(conn)\n",
    "        except Exception as e:\n",
    "            print(f'Connecting to database failed. {e}')\n",
    "            return []\n",
    "        \n",
    "        # SQL query to execute \n",
    "        query = f'delete from {table}' \n",
    "        cursor = conn.cursor() \n",
    "        try: \n",
    "            cursor.execute(query)\n",
    "            conn.commit() \n",
    "        except (Exception, psycopg2.DatabaseError) as error: \n",
    "            print(\"Error: %s\" % error) \n",
    "            conn.rollback()  \n",
    "            \n",
    "        cursor.close()  \n",
    "    \n",
    "    def run_dml_statement(self, df: str, table: str, vars=None): \n",
    "        \n",
    "        try:\n",
    "            conn = self._get_database_connection()\n",
    "            register_vector(conn)\n",
    "        except Exception as e:\n",
    "            print(f'Connecting to database failed. {e}')\n",
    "            return []\n",
    "        \n",
    "        tuples = [tuple(x) for x in df.to_numpy()] \n",
    "  \n",
    "        cols = ','.join(list(df.columns)) \n",
    "        # SQL query to execute \n",
    "        query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols) \n",
    "        cursor = conn.cursor() \n",
    "        try: \n",
    "            extras.execute_values(cursor, query, tuples) \n",
    "            conn.commit() \n",
    "        except (Exception, psycopg2.DatabaseError) as error: \n",
    "            print(\"Error: %s\" % error) \n",
    "            conn.rollback() \n",
    "\n",
    "        cursor.close()  \n",
    "        \n",
    "    def run_insert_statement(self, table_name: str, data_list: list):\n",
    "        try:\n",
    "            conn = self._get_database_connection()\n",
    "            register_vector(conn)\n",
    "        except Exception as e:\n",
    "            print(f'Connecting to database failed. {e}')\n",
    "            return\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            execute_values(cursor, f\"\"\"INSERT INTO {table_name} (ticket_id, ticket_comment, ticket_sentence_hash, module, product,\n",
    "                                   sentence_source, ticket_status, sentence_embedding, created_at, updated_at, sentence) VALUES %s ON CONFLICT DO NOTHING\"\"\", data_list)\n",
    "            conn.commit()\n",
    "            print(f'Sentences added to dabatase successfully.')\n",
    "        except Exception as e:\n",
    "            print(f'Inserting {len(data_list)} rows into database failed. {e}')\n",
    "            conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf309f19-07e1-4ed7-8125-1e9c94fbc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "    \n",
    "    def run_select_bigquery(select_statement: str):\n",
    "        GOOGLE_CREDENTIAL=''\n",
    "        credentials = Credentials.from_service_account_info(json.loads(base64.b64decode(GOOGLE_CREDENTIAL)))\n",
    "\n",
    "        project_id = 'labs-poc'\n",
    "        client = bigquery.Client(credentials= credentials,project=project_id)\n",
    "\n",
    "        try:\n",
    "            # Perform a query.\n",
    "            query_job = client.query(select_statement)  # API request\n",
    "            result = query_job.result()\n",
    "        except Exception as e:\n",
    "            print(f'Fetching resuls from database failed. {e}\\nSelect statement: {select_statement}')\n",
    "            raise\n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "859a6594-2fe0-4d6d-be8d-41c8fdb043c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic_between_asterisks(text):\n",
    "    pattern = r'\\*\\*(.*?)\\*\\*'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e721695d-d63b-4f7a-9581-9f9b793a5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_summary(ticket: str):\n",
    "    docs_list = [Document(page_content=str(ticket))]\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=512, chunk_overlap=0\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "    prompt_template = (\n",
    "        \"A seguinte passagem representa uma conversa entre um cliente e um agente de suporte técnico:\"\n",
    "        \"---------------------\\n\"\n",
    "        \"{context}\\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"Dada a conversa forneça um tópico central e único do problema que foi discutido\"\n",
    "        \"Desconsidere nomes, URLs, anexos, datas.\\n\"\n",
    "    )\n",
    "    template = PromptTemplate(input_variables=[\"context\"], template=prompt_template)\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"gpt-4o-2024-05-13\",\n",
    "        openai_api_base='https://proxy.dta.totvs.ai/',\n",
    "        openai_api_key=\"\"\n",
    "    )\n",
    "    qa_chain = load_qa_chain(llm, prompt=template)\n",
    "    context = {'input_documents': doc_splits}\n",
    "    output = qa_chain(context)\n",
    "    output = output.get('output_text')\n",
    "    out = extract_topic_between_asterisks(output)\n",
    "    return out if out else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5009a208-3cd6-429f-8bbb-b3cd356ce919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(text):\n",
    "    cleaned_text = re.sub(r'\\d+\\.\\s*', '', text)\n",
    "    return ' '.join(cleaned_text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb924dd4-5ac1-495e-aa73-8dccb810aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_keywords(ticket: str):\n",
    "    docs_list = [Document(page_content=str(ticket))]\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=512, chunk_overlap=0\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(docs_list)\n",
    "    prompt_template = prompt_template = (\n",
    "        \"A seguinte passagem representa uma conversa entre um cliente e um agente de suporte técnico:\"\n",
    "        \"---------------------\\n\"\n",
    "        \"{context}\\n\"\n",
    "        \"---------------------\\n\"\n",
    "        \"Dada a conversa forneça 8 palavras chaves principais que descrevam o problema que foi discutido\"\n",
    "        \"Desconsidere nomes, URLs, anexos, datas.\\n\"\n",
    "    )\n",
    "    template = PromptTemplate(input_variables=[\"context\"], template=prompt_template)\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model=\"gpt-4o-2024-05-13\",\n",
    "        openai_api_base='https://proxy.dta.totvs.ai/',\n",
    "        openai_api_key=\"\"\n",
    "    )\n",
    "    qa_chain = load_qa_chain(llm, prompt=template)\n",
    "    context = {'input_documents': doc_splits}\n",
    "    output = qa_chain(context)\n",
    "    output = output.get('output_text')\n",
    "    return clean_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bec70f2-b394-4afe-bae6-1117a423741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_statement = (\"\"\"\n",
    "                    WITH tickets_all AS (\n",
    "                        SELECT\n",
    "                            ticket_id,\n",
    "                            STRING_AGG(ticket_comment, '\\u2561') AS ticket_comment,\n",
    "                            MAX(subject) AS subject,\n",
    "                            '' AS summary,\n",
    "                            '' ticket_sentence_hash,\n",
    "                            MAX(module_name) AS module,\n",
    "                            MAX(product_name) AS product,\n",
    "                            '' AS sentence_source,\n",
    "                            MAX(ticket_status) AS ticket_status,\n",
    "                            '[1,2,3]' AS sentence_embedding,\n",
    "                            MAX(created_at) AS created_at,\n",
    "                            MAX(updated_at) AS updated_at,\n",
    "                        FROM\n",
    "                            `labs-poc`.custom_data.tickets tr\n",
    "                        GROUP BY\n",
    "                            ticket_id\n",
    "                        ),\n",
    "\n",
    "                        first_contact AS (\n",
    "                        SELECT\n",
    "                            ts.ticket_comment AS first_comment,\n",
    "                            ts.ticket_id\n",
    "                        FROM\n",
    "                            `labs-poc`.custom_data.tickets ts\n",
    "                        INNER JOIN\n",
    "                            tickets_all tr\n",
    "                        ON\n",
    "                            ts.ticket_id = tr.ticket_id\n",
    "                        QUALIFY ROW_NUMBER() OVER(PARTITION BY ts.ticket_id ORDER BY ts.comment_created_at) = 1\n",
    "                        )\n",
    "\n",
    "                        SELECT\n",
    "                            ta.*,\n",
    "                            tr.first_comment\n",
    "                        FROM\n",
    "                            tickets_all ta\n",
    "                        INNER JOIN\n",
    "                            first_contact tr\n",
    "                            ON tr.ticket_id = ta.ticket_id\n",
    "\n",
    "                    \"\"\")\n",
    "# Faz a leitura dos daods no BQ\n",
    "df = LoadData.run_select_bigquery(select_statement).to_dataframe()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b224a7eb-d5b3-4912-915a-083b6ac3f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f2c61f-bda7-41cf-ba7b-09fa3ce98386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticket_id', 'ticket_comment', 'subject', 'summary',\n",
       "       'ticket_sentence_hash', 'module', 'product', 'sentence_source',\n",
       "       'ticket_status', 'sentence_embedding', 'created_at', 'updated_at',\n",
       "       'first_comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d05a6ead-1f45-4b2f-a349-2ba3d7f7586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = df.copy()\n",
    "df_keywords = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8b01c30-69bf-4ce1-b080-d5036fc6c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary['sentence'] = df_summary['ticket_comment'].apply(get_ticket_summary)\n",
    "df_summary['sentence_source'] = 'summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db37dc1f-b035-4f2e-abb4-7dc224a9f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords['sentence'] = df_keywords['ticket_comment'].apply(get_ticket_keywords)\n",
    "df_keywords['sentence_source'] = 'keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "979ed753-36f9-40e8-a626-a0e475b32824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fb65ef6-021e-4022-bf95-56c43eff0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subject['sentence'] = df_subject['subject']\n",
    "df_subject['sentence_source'] = 'subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "468e338e-f0cf-4d6a-9c5f-34732ed7b3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 14)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = pd.concat([df_summary, df_keywords, df_subject])\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37c50969-a3e6-45fa-8784-981beba0c07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>ticket_comment</th>\n",
       "      <th>subject</th>\n",
       "      <th>summary</th>\n",
       "      <th>ticket_sentence_hash</th>\n",
       "      <th>module</th>\n",
       "      <th>product</th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>ticket_status</th>\n",
       "      <th>sentence_embedding</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>first_comment</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>19536126</td>\n",
       "      <td>(13:43:10) *** MARIA ANALICE DE OLIVEIRA entro...</td>\n",
       "      <td>* Instalação Biblioteca RM</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Configuração</td>\n",
       "      <td>Framework (Linha RM)</td>\n",
       "      <td>summary</td>\n",
       "      <td>closed</td>\n",
       "      <td>[1,2,3]</td>\n",
       "      <td>2024-03-06 13:43:13</td>\n",
       "      <td>2024-03-15 16:07:41</td>\n",
       "      <td>Conversa com MARIA ANALICE DE OLIVEIRA  URL: h...</td>\n",
       "      <td>O tópico central e único do problema discutido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>19004780</td>\n",
       "      <td>Segue demanda para analise. Bom trabalho!╡Equi...</td>\n",
       "      <td>Erro ao integrar evento</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Segurança e Saúde Ocupacional (SSO)</td>\n",
       "      <td>TOTVS RH (Linha RM)</td>\n",
       "      <td>subject</td>\n",
       "      <td>closed</td>\n",
       "      <td>[1,2,3]</td>\n",
       "      <td>2024-01-11 10:05:47</td>\n",
       "      <td>2024-01-23 18:10:50</td>\n",
       "      <td>Bom dia !\\r \\r Ao realizar a integração de um ...</td>\n",
       "      <td>Erro ao integrar evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>19371366</td>\n",
       "      <td>(11:58:51) *** Joabson de Brito Cardoso entrou...</td>\n",
       "      <td>Formula Visual Criar Coluna na Visão de dados</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RM Integração</td>\n",
       "      <td>TOTVS Backoffice (Linha RM)</td>\n",
       "      <td>subject</td>\n",
       "      <td>closed</td>\n",
       "      <td>[1,2,3]</td>\n",
       "      <td>2024-02-19 11:58:55</td>\n",
       "      <td>2024-02-28 16:09:38</td>\n",
       "      <td>Conversa com Joabson de Brito Cardoso  URL: ht...</td>\n",
       "      <td>Formula Visual Criar Coluna na Visão de dados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>17817875</td>\n",
       "      <td>Boa noite!  Conforme conversamos via chat, a f...</td>\n",
       "      <td>Acessar espelho de ponto 2018 - mensagem-&gt; não...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Automação de Ponto (CHRONUS)</td>\n",
       "      <td>TOTVS RH (Linha RM)</td>\n",
       "      <td>summary</td>\n",
       "      <td>closed</td>\n",
       "      <td>[1,2,3]</td>\n",
       "      <td>2023-08-15 17:55:31</td>\n",
       "      <td>2023-08-25 15:10:56</td>\n",
       "      <td>Conversa com Mylena Tito Barbosa  URL: https:/...</td>\n",
       "      <td>O tópico central e único do problema discutido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>17940848</td>\n",
       "      <td>na hora de validar o ambiente mobile está dand...</td>\n",
       "      <td>Configuração do APPMNTNG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Manutenção de ativos (SIGAMNT)</td>\n",
       "      <td>TOTVS Manufatura (Linha Protheus)</td>\n",
       "      <td>keywords</td>\n",
       "      <td>closed</td>\n",
       "      <td>[1,2,3]</td>\n",
       "      <td>2023-08-31 09:58:31</td>\n",
       "      <td>2023-09-12 11:10:59</td>\n",
       "      <td>na hora de validar o ambiente mobile está dand...</td>\n",
       "      <td>Licença MNTNG Código 3033 License Server Virtu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticket_id                                     ticket_comment  \\\n",
       "40    19536126  (13:43:10) *** MARIA ANALICE DE OLIVEIRA entro...   \n",
       "164   19004780  Segue demanda para analise. Bom trabalho!╡Equi...   \n",
       "45    19371366  (11:58:51) *** Joabson de Brito Cardoso entrou...   \n",
       "117   17817875  Boa noite!  Conforme conversamos via chat, a f...   \n",
       "150   17940848  na hora de validar o ambiente mobile está dand...   \n",
       "\n",
       "                                               subject summary  \\\n",
       "40                          * Instalação Biblioteca RM           \n",
       "164                            Erro ao integrar evento           \n",
       "45       Formula Visual Criar Coluna na Visão de dados           \n",
       "117  Acessar espelho de ponto 2018 - mensagem-> não...           \n",
       "150                           Configuração do APPMNTNG           \n",
       "\n",
       "    ticket_sentence_hash                               module  \\\n",
       "40                                               Configuração   \n",
       "164                       Segurança e Saúde Ocupacional (SSO)   \n",
       "45                                              RM Integração   \n",
       "117                              Automação de Ponto (CHRONUS)   \n",
       "150                            Manutenção de ativos (SIGAMNT)   \n",
       "\n",
       "                               product sentence_source ticket_status  \\\n",
       "40                Framework (Linha RM)         summary        closed   \n",
       "164                TOTVS RH (Linha RM)         subject        closed   \n",
       "45         TOTVS Backoffice (Linha RM)         subject        closed   \n",
       "117                TOTVS RH (Linha RM)         summary        closed   \n",
       "150  TOTVS Manufatura (Linha Protheus)        keywords        closed   \n",
       "\n",
       "    sentence_embedding          created_at          updated_at  \\\n",
       "40             [1,2,3] 2024-03-06 13:43:13 2024-03-15 16:07:41   \n",
       "164            [1,2,3] 2024-01-11 10:05:47 2024-01-23 18:10:50   \n",
       "45             [1,2,3] 2024-02-19 11:58:55 2024-02-28 16:09:38   \n",
       "117            [1,2,3] 2023-08-15 17:55:31 2023-08-25 15:10:56   \n",
       "150            [1,2,3] 2023-08-31 09:58:31 2023-09-12 11:10:59   \n",
       "\n",
       "                                         first_comment  \\\n",
       "40   Conversa com MARIA ANALICE DE OLIVEIRA  URL: h...   \n",
       "164  Bom dia !\\r \\r Ao realizar a integração de um ...   \n",
       "45   Conversa com Joabson de Brito Cardoso  URL: ht...   \n",
       "117  Conversa com Mylena Tito Barbosa  URL: https:/...   \n",
       "150  na hora de validar o ambiente mobile está dand...   \n",
       "\n",
       "                                              sentence  \n",
       "40   O tópico central e único do problema discutido...  \n",
       "164                            Erro ao integrar evento  \n",
       "45       Formula Visual Criar Coluna na Visão de dados  \n",
       "117  O tópico central e único do problema discutido...  \n",
       "150  Licença MNTNG Código 3033 License Server Virtu...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0aa9f4c7-7669-42fb-8557-5581a6093d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        openai_api_base='https://proxy.dta.totvs.ai/',\n",
    "        openai_api_key=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d137872-4386-4eb1-9e33-3ac7307d77b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando os embeddings para 509 novas sentenças.\n"
     ]
    }
   ],
   "source": [
    "sentences_pending = dff[\"sentence\"].unique()\n",
    "print(f'Criando os embeddings para {len(sentences_pending)} novas sentenças.')\n",
    "embeddings_pending = model.embed_documents(sentences_pending)\n",
    "sentence_to_embedding = dict(zip(sentences_pending, embeddings_pending))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "adf59ddb-2fce-4a58-8f2e-56fd08a1e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['sentence_embedding'] = dff[\"sentence\"].apply(lambda x: sentence_to_embedding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2dcaa7b-0bbb-4b1d-bc38-ce592732d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_hash(ticket_id, sentence):\n",
    "    hash_concat = str(ticket_id) + sentence\n",
    "    return hashlib.md5(hash_concat.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e2d3c82-d876-4dac-b19c-2e340310269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['ticket_sentence_hash'] = dff.apply(lambda row: get_sentence_hash(row['ticket_id'], row['sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be36abdf-4768-4c7d-8b12-6d4120c2963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [(row['ticket_id'], \n",
    "              row['ticket_comment'], \n",
    "              row['ticket_sentence_hash'],\n",
    "              row['module'], \n",
    "              row['product'],\n",
    "              row['sentence_source'],\n",
    "              row['ticket_status'],\n",
    "              row['sentence_embedding'], \n",
    "              row['created_at'], \n",
    "              row['updated_at'], \n",
    "              row['sentence']) for _, row in dff.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57b64971-7dde-4efd-a0c7-bb3e861a93aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences added to dabatase successfully.\n"
     ]
    }
   ],
   "source": [
    "DatabaseService().run_insert_statement('tickets_embeddings_summary', data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd985a-a4a8-4b3f-8fde-04758759b684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carolina",
   "language": "python",
   "name": "carolina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
